{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f568bf5-dcb6-4353-bcad-e7285cdbf1f8",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d6e701-3897-4914-8b02-fbef316bc862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from random import randint\n",
    "import concurrent.futures\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e14d71-6be8-4e70-985e-a9bb1f2b0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define the header to get the text in a specifique language. in my case us english\n",
    "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854caef0-d923-4bba-acaa-9b097760e1dd",
   "metadata": {},
   "source": [
    "## Create a function to get pages' url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea4467e-8de1-428d-9e90-f618a19aae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of url to get the url of 40pages containing 10thousand movies\n",
    "pages = [str(i) for i in range(1,10000,250)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01995c89-55d0-4fd1-ae67-21415057d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for page in pages:\n",
    "    p_url = 'https://www.imdb.com/search/title/?at=0&num_votes=5000,&sort=user_rating,desc&count=250&start=' + page + '&title_type=feature'\n",
    "            \n",
    "    urls.append(p_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c59553a-d944-4878-9c4c-f46264f7cd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this represents the total number of pages nowing that each page contains 250 movies\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91defea-8184-4741-a19b-5e6a8eff12dd",
   "metadata": {},
   "source": [
    "## Create a function to get movies' url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a7d5e9d-f611-49da-bebb-b5f5b2ee7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchmovies_link(url):\n",
    "    \n",
    "    ''' the fetchmovies_link function retrieves all the movies\n",
    "    link in each pages url is the object representing a page link '''\n",
    "    \n",
    "    response = req.get(url, headers=headers)\n",
    "    html = bs(response.text, 'html.parser')\n",
    "    movies = html.find_all('div', {'class':'lister-item mode-advanced'})\n",
    "\n",
    "    baseurl ='https://www.imdb.com'\n",
    "#     movies_link = []\n",
    "    \n",
    "    for movie in movies:\n",
    "\n",
    "        url1 = baseurl + movie.find('a')['href']\n",
    "        movies_link.append(url1)\n",
    "        \n",
    "    return(movies_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0326cb8-620f-471c-911d-f8aa026e83fe",
   "metadata": {},
   "source": [
    "#### Use of concurrence to speed up my fetchmovies_link function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bd007db-5693-49a1-a54a-8e1d3e4fbc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 54.6239767 seconds\n"
     ]
    }
   ],
   "source": [
    "# t1 determines the time at start and t2 the end time for each thread and thier difffernece gives us the total computation time\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = executor.map(fetchmovies_link, urls)\n",
    "    \n",
    "#     we obtain our results by appling a loop and storing them in a list\n",
    "    movies_link = [] \n",
    "    \n",
    "#     for result in results:\n",
    "#         links.append(result)\n",
    "        \n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f'finished in {t2 - t1} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db0a687c-2962-46f8-a875-ac8ca4389b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we have 10000 movie's links for for all the 40 pages\n",
    "len(movies_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51006c63-8f9b-42f4-b05d-dc079a123b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.imdb.com/title/tt0070511/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if this actually gives out a link and compare on the web side.\n",
    "movies_link[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3abdff04-495d-48ba-8197-bf7d71981f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "links    10000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "list_movieslink = pd.DataFrame(movies_link, columns = ['links'])\n",
    "list_movieslink.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a7bf0f-cf2d-4436-b186-d4d678c6ea1d",
   "metadata": {},
   "source": [
    "## Create a function to get our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "334a62a6-bd4c-4827-b3a7-0e41513d6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(movies_link):\n",
    "#     imdb = []\n",
    "    \n",
    "    imdb_data = {'Name' : None,\n",
    "                'Directors' : [],\n",
    "                'Writers': [],\n",
    "                'Imdb_rating' : None,\n",
    "                'Score' : None,\n",
    "                'Genres' : [],\n",
    "                'Votes' : None,\n",
    "                'Runtime' : None,\n",
    "                'Country' : None,\n",
    "                'Release_date' : None,\n",
    "                'Budget' : None,\n",
    "                'Opening_weekend' : None,\n",
    "                'Gross_USA' : None,\n",
    "                'Worldwide_gross' : None,\n",
    "                'Runtime' : None,\n",
    "                'Sound_mix' : None,\n",
    "                'Color' : None,\n",
    "                'Aspect_ratio' : None,\n",
    "                'Film_location' : [],\n",
    "                'Summary' : None,\n",
    "                'User_review': None,\n",
    "                'Critic_review': None}\n",
    "    \n",
    "    \n",
    "#     imdb_data = imdb_data_b.copy() \n",
    "    \n",
    "\n",
    "    \n",
    "    response = req.get(url = movies_link, headers = headers)\n",
    "    html = bs(response.text, 'html.parser')\n",
    "    \n",
    "    body = html.find('div', class_='pagecontent')\n",
    "    \n",
    "    genres = body.find_all('div', {'class':'see-more inline canwrap'})\n",
    "    \n",
    "    imdb_data['Summary'] = body.find('div', class_='summary_text').text.strip()\n",
    "    \n",
    "    for gen in genres:\n",
    "        if gen.h4.text == 'Genres:':\n",
    "            genres_all = gen.find_all('a')\n",
    "            for gen_all in genres_all:\n",
    "                imdb_data['Genres'].append(gen_all.text) \n",
    "    \n",
    "    imdb_data['Name'] = body.find('div', class_ = 'title_wrapper').h1.text\n",
    "    \n",
    "\n",
    "    scores = body.find('div', class_ = 'metacriticScore score_favorable titleReviewBarSubItem')\n",
    "    if not scores:\n",
    "        imdb_data['Score'] = 'xxx'\n",
    "    else:\n",
    "        imdb_data['Score'] = float(scores.span.text)\n",
    "        \n",
    "    imdb_data['Imdb_rating'] = float(body.find('span', {'itemprop' : 'ratingValue'}).text)\n",
    "    imdb_data['Votes'] = int(body.find('span', {'class' : 'small'}).text.replace(',', ''))\n",
    "    \n",
    "    \n",
    "    oscar = body.find('span', {'class' : 'awards-blurb'})\n",
    "    if not oscar:\n",
    "        imdb_data['Oscars'] = 'xxx'\n",
    "    else:\n",
    "        if ('Oscars' in oscar.text) & ('Won' in oscar.text):\n",
    "            imdb_data['Oscars'] = int(oscar.text[25:31])\n",
    "        else:\n",
    "            imdb_data['Oscars'] = 'xxx'\n",
    "            \n",
    "    review = body.find('div', class_ = 'titleReviewBarItem titleReviewbarItemBorder')\n",
    "    imdb_data['User_review'] = review.a.text[:-4].replace(',','')\n",
    "    \n",
    "    if not review.find_all('a')[1].text[:-6].replace(',',''):\n",
    "        imdb_data['Critic_review'] = 'xxx'\n",
    "    else:\n",
    "        imdb_data['Critic_review'] = review.find_all('a')[1].text[:-6].replace(',','')            \n",
    "    subtext = body.find_all('div', {'class' : 'titleReviewBarItem'})\n",
    "    \n",
    "#     for sub in subtext:\n",
    "#         if not sub.find('div', class_ = ''):\n",
    "#             imdb_data['Popularity'] = 'xxx'\n",
    "#         else:\n",
    "#             pop = sub.find('div', class_ = '').text.strip()\n",
    "#             if pop == 'Popularity':\n",
    "#                 imdb_data['Popularity'] = int(sub.find('span', class_ =  'subText').text[:24])\n",
    "                \n",
    "# #             elif pop == 'Reviews':\n",
    "# #                 rev = sub.find('span', class_ =  'subText').find_all('a')\n",
    "# #                 imdb_data['User_review'] = int(rev[0].text[:-4].replace(',',''))\n",
    "# #                 if not rev[1]:\n",
    "# #                     imdb_data['Critic_review'] = 'xxx'\n",
    "# #                 else:\n",
    "# #                     imdb_data['Critic_review'] = int(rev[1].text[:-6].replace(',',''))            \n",
    "\n",
    "        \n",
    "        \n",
    "    teams = body.find_all('div', class_ = 'credit_summary_item')\n",
    "\n",
    "    for team in teams:\n",
    "        \n",
    "        if not team.h4:\n",
    "            crew = None\n",
    "            continue\n",
    "        else :\n",
    "            crew = team.h4.text.strip()\n",
    "        if crew == 'Directors:':\n",
    "            dires = team.find_all('a')\n",
    "            for dire in dires:\n",
    "                imdb_data['Directors'].append(dire.text)\n",
    "        elif crew == 'Writers:':\n",
    "            writs = team.find_all('a')\n",
    "            for writ in writs:\n",
    "                imdb_data['Writers'].append(writ.text)\n",
    "\n",
    "\n",
    "    details = body.find('div', {'class' : 'article', 'id' : 'titleDetails'})\n",
    "    infs = details.find_all('div', class_ = 'txt-block')\n",
    "\n",
    "\n",
    "    for inf in infs:   \n",
    "        if not inf.h4:\n",
    "            det = None\n",
    "#             continue\n",
    "        else :\n",
    "            det = inf.h4.text.strip()\n",
    "        if det == 'Country:':\n",
    "            imdb_data['Country'] = inf.a.text\n",
    "        elif det == 'Release Date:':\n",
    "            imdb_data['Release_date'] = inf.contents[2].strip()\n",
    "        elif det == 'Budget:':\n",
    "            imdb_data['Budget'] = inf.contents[2].strip()\n",
    "        elif det == 'Opening Weekend USA:':\n",
    "            imdb_data['Opening_weekend'] = inf.contents[2].strip()\n",
    "        elif det == 'Gross USA:':\n",
    "            imdb_data['Gross_USA'] = inf.contents[2].strip()\n",
    "        elif det == 'Cumulative Worldwide Gross:':\n",
    "            imdb_data['Worldwide_gross'] = inf.contents[2].strip()\n",
    "        elif det == 'Runtime:':\n",
    "            imdb_data['Runtime'] = inf.time.text.replace('min','').strip()\n",
    "        elif det == 'Sound Mix:':\n",
    "            imdb_data['Sound_mix'] = inf.a.text.strip()\n",
    "        elif det == 'Color:':\n",
    "            imdb_data['Color'] = inf.a.text.strip()\n",
    "        elif det == 'Aspect Ratio:':\n",
    "            imdb_data['Aspect_ratio'] = inf.contents[2].strip()        \n",
    "        elif det == 'Filming Locations:':\n",
    "            if not inf.find('span', class_ = 'see-more inline'):\n",
    "                fil_loc = inf.a\n",
    "                imdb_data['Film_location'] = fil_loc.text\n",
    "\n",
    "            else:\n",
    "                see_more = inf.find('span', class_ = 'see-more inline')\n",
    "\n",
    "                \n",
    "                loc_url = movies_link + see_more.find('a')['href']\n",
    "                response2 = req.get(loc_url, headers = headers)\n",
    "                html2 = bs(response2.text, 'html.parser')\n",
    "                tab_loc = html2.find('section',{'id':'filming_locations'})                                          #parser ralenti le code d'une seconde\n",
    "                locs = tab_loc.find_all('dt')\n",
    "\n",
    "                for loc in locs:\n",
    "                    imdb_data['Film_location'].append(loc.a.text[:-1])\n",
    "                    \n",
    "    imdb.append(imdb_data)\n",
    "    return(imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62273ea-19a3-40d8-83b6-ba992354acf2",
   "metadata": {},
   "source": [
    "#### Use of concurrence to speed up my fetchmovies_link function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e23fdf0-a24e-4b86-b13e-d1e327a4fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.perf_counter()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results1 = executor.map(data, movies_link)\n",
    "    imdb = []\n",
    "        \n",
    "t2 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bcfa51a4-73ab-4038-a9f5-fa194471db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished scrapping 9942 movie(s) in 2250.8200889 seconds(37.51366814833333 minute(s))\n",
      "that is 0.2263951004727419 second to scrap one movie and \n",
      "this means 4.417056720361316 movie(s) is scrapped every second\n"
     ]
    }
   ],
   "source": [
    "print(f'''finished scrapping {len(imdb)} movie(s) in {t2 - t1} seconds({(t2 - t1)/60} minute(s))\n",
    "that is {(t2 - t1)/len(imdb)} second to scrap one movie and \n",
    "this means {len(imdb)/(t2 - t1)} movie(s) is scrapped every second''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f56f2a0a-a08f-4d25-973a-b4aab7108dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9942"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if we still have 10thousand indexs\n",
    "len(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c118027-9f26-474f-bca5-d66094d3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_imdb = pd.DataFrame(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e1f5c891-9bca-4c6e-8387-4f69b37fe62a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9942, 22)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_imdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e71cacde-6d1e-4f1e-b51b-630d73588fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_imdb.to_csv('Data_imdb.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
